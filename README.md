# TP1-NLP
This was a research assignment for the class on Natural Language Processing (UFMG-2019) with the 
goal to avaluate different constructions of neural language models.  

For the task, we tested some different hyperparameters and analysed their impact on the overall 
performance of the language models. The test was: given three words (provided on question-words.txt),
the model should predict the next one. The performance was mesured with the cosine distance between
the predicted word and the correct one.
The results analysis are on the pdf file (in Portuguese) and the entire code used is available.
